{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Instituto Federal de Educação, Ciência e Tecnologia da Paraíba\n",
    "                        Engenharia de Computação\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                     PREDIÇÃO DE DADOS DE SAÚDE\n",
    "                      USANDO REGRESSÃO LINEAR\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     JOÃO VICTOR SOARES DE ALMEIDA\n",
    "                     MANOEL MARCELO CARVALHO JUNIOR\n",
    "                        \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     CAMPINA GRANDE - 2019\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1 Fundamentação do Problema</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A análise de Regressão consiste na realização de uma análise estatística com objetivo de verificar a existência de uma relação funcional entre uma variável dependente com uma ou \n",
    "mais variáveis independentes. Para tentar estabelecer uma equação que representa o fenômeno em estudo pode-se fazer um gráfico, chamado de diagrama de dispersão, para verificar como se comportam os valores da variável dependente (Y) em função da variável independente (X). O comportamento de **Y em relação à X** pode-se apresentar de diversas maneiras: linear, quadrático, cúbico, exponencial, logarítmico, entre outros. Para se estabelecer o modelo para explicar o fenômeno, deve-se verificar qual tipo de curva e equação de um modelo matemático que mais se aproxime dos pontos representados no diagrama de dispersão.\n",
    "\n",
    "Ademais, no primeiro momento utilizaremos o **Método dos Mínimos Quadrados(MMQ)**, que consiste em uma técnica de otimização matemática que procura encontrar o melhor ajuste para um conjunto de dados tentando minimizar a soma dos quadrados das diferenças entre o valor estimado e os dados observados (tais diferenças são chamadas resíduos). Consiste em um estimador que minimiza a soma dos quadrados dos resíduos da regressão, de forma a maximizar o grau de ajuste do modelo aos dados observados.Um requisito para o método dos mínimos quadrados é que o fator imprevisível (erro) seja distribuído aleatoriamente e essa distribuição seja normal. \n",
    "\n",
    "No segundo momento, utilizaremos **Equações Normais (Cholesky), Fatoração QR e Decomposição em Valores Singulares (SVD)**. Abaixo explicaremos melhor a motivação para utilizar esses métodos.\n",
    ">- Em Álgebra Linear, a decomposição de Cholesky é uma decomposição de uma matriz hermitiana (matriz transposta conjugada) e positiva definida no produto de uma matriz triangular inferior e sua matriz adjunta. Esse método permite uma otimização em relação ao custo computacional e pode ser descrita como:\n",
    "    - $A^TA x = A^T b \\Rightarrow (A^TA)^{-1}A^T \\Rightarrow A^TA = R^TR$\n",
    "    \n",
    ">- Em álgebra linear, uma decomposição QR (também chamada de fatoração QR) de uma matriz é uma decomposição de uma matriz A em um produto A = QR de uma matriz ortogonal Q e uma matriz triangular superior R. A decomposição QR é usado frequentemente para resolver o problema de mínimos quadrados linear e é a base para um determinado algoritmo de autovalores, o algoritmo QR. Sua descrição matemática se resume a:\n",
    "    - $ A x = b \\Rightarrow A = QR \\Rightarrow Q R x = b$\n",
    "    \n",
    ">- Em álgebra linear, a decomposição em valores singulares ou singular value decomposition (SVD) é a fatoração de uma matriz real ou complexa, com diversas aplicações importantes em processamento de sinais e estatística. Formalmente, a decomposição em valores singulares de uma matriz $m×n$ real ou complexa $M$ é uma fatoração ou fatorização na forma:\n",
    "    - $A x = b \\Rightarrow A = U\\Sigma V \\Rightarrow \\Sigma  w = U^T b \\Rightarrow x = V^T$\n",
    "    - Dentre as aplicações que envolvem a SVD estão o cálculo da pseudoinversa, ajuste (fitting) de dados por mínimos quadrados, aproximação de matrizes, e a determinação do posto, imagem e núcleo de uma matriz.\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "A regressão, em geral,  tem como objetivo tratar de um valor que não conseguimos estimar inicialmente. Não obstante, utilizaremos da ferramenta Regressão Linear para analisar um conjunto de dados de pacientes com diabetes. Os dados consistem em 442 amostras e 10 variáveis - **todas são características fisiológicas** -. A variável dependente é uma medida quantitativa da progressão da doença um ano após o início.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2 Descrição do Problema </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regressão linear é chamada \"linear\" porque se considera que a relação da resposta às variáveis é uma função linear de alguns parâmetros. Os modelos de regressão que não são uma função linear dos parâmetros se chamam modelos de regressão não-linear. Sendo uma das primeiras formas de análise regressiva a ser estudada rigorosamente, e usada extensamente em aplicações práticas. Isso acontece porque modelos que dependem de forma linear dos seus parâmetros desconhecidos, são mais fáceis de ajustar que os modelos não-lineares aos seus parâmetros, e porque as propriedades estatísticas dos estimadores resultantes são fáceis de determinar.\n",
    "\n",
    "Modelos de regressão linear são frequentemente ajustados usando a abordagem dos mínimos quadrados, mas que também pode ser montada de outras maneiras, tal como minimizando a *falta de ajuste* em alguma outra norma (com menos desvios absolutos de regressão), ou através da minimização de uma penalização da versão dos mínimos quadrados. Por outro lado, a abordagem de mínimos quadrados pode ser utilizado para ajustar a modelos que não são modelos lineares. Assim, embora os termos mínimos quadrados e modelo linear estejam intimamente ligados, eles não são sinônimos.\n",
    "\n",
    "- #### Equação da Regressão Linear\n",
    " $$y_i = \\alpha + \\beta X_i + \\epsilon_i$$\n",
    "\n",
    "em que:\n",
    "- $y_i$: Variável dependente, representa o que o modelo tentará prever,\n",
    "- $\\alpha$: É uma constante, que representa a intercptação da reta com o eixo - vertical;\n",
    "- $\\beta$: Representa o coeficiente angular(inclinação) em relação à variavél\n",
    "  $\\beta$\n",
    "- $X_i$; Variável independente\n",
    "- $\\epsilon_i$: Representa todos os fatores residuais mais os possíveis erros de medição. O seu comportamento é aleatório, d evido à natureza dos fatores que encerra. Para que essa fórmula possa ser aplicada, os erros devem satisfazer determinadas hipóteses, que são:\n",
    "    - Terem distribuição normal\n",
    "    - Mesma variância $\\sigma^2$\n",
    "    \n",
    "- #### Notação Matricial\n",
    "  \n",
    "A equação acima pode ser reescrita em forma matricial, como:\n",
    "\n",
    "$$y = X\\beta + \\epsilon$$\n",
    "\n",
    "Em que $y$ é uma matriz de  ${\\displaystyle n\\times 1}$ observações, X é uma matriz de tamanho ${\\displaystyle n\\times p+1}$ sendo a primeira coluna com valores sempre = 1, representando a constante $\\alpha$, e $p$ é a quantidade de variáveis explicativas), $\\beta$ é uma matriz de ${\\displaystyle p+1\\times 1}$ variáveis explicativas(sendo que $\\beta_0$ representa a constante $\\alpha$) e $\\epsilon$ é uma matriz de ${\\displaystyle n\\times 1}$ de resíduos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf y = \\begin{bmatrix}\n",
    "y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n",
    "\\end{bmatrix} ,\n",
    "\\qquad \\mathbf {X}=\\begin{bmatrix}\n",
    "1 & X_{11} & X_{12} & \\cdots & X_{1p} \\\\\n",
    "1 & X_{21} & X_{22} & \\cdots & X_{2p} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & X_{n1} & X_{n2} & \\cdots & X_{np}\n",
    "\\end{bmatrix} ,\n",
    "\\qquad \\boldsymbol \\beta = \\begin{bmatrix}\n",
    "\\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_p \\end{bmatrix} ,\n",
    "\\qquad \\boldsymbol \\varepsilon = \\begin{bmatrix}\n",
    "\\varepsilon_1 \\\\ \\varepsilon_2 \\\\ \\vdots \\\\ \\varepsilon_n \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo prático - Método MMQ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na implementação abaixo iremos implementar o conceito descrito acima sobre Regressão Linear, faremos um relacionamento entre duas variáveis. Dado $x  e  y$ iremos modelar essa relação. Sabemos que *y* será a nossa variável dependente de *x* e *x* será nossa variável independente. Utilizaremos sklearn que é uma biblioteca aberta de ML para Python e  ela inclui vários algoritmos de classificação, regressão e agrupamento incluindo máquinas de vetores de suporte, florestas aleatórias, gradient boosting, k-means e DBSCAN, e é projetada para interagir com as bibliotecas Python numéricas e científicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.86342983]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "\n",
    "#digit dataset from sklearn\n",
    "digits = datasets.load_digits()\n",
    "#create the LinearRegression model\n",
    "clf = linear_model.LinearRegression()\n",
    "#set training set\n",
    "x, y = digits.data[:-1], digits.target[:-1]\n",
    "#train model\n",
    "clf.fit(x, y)\n",
    "#predict\n",
    "y_pred = clf.predict([digits.data[-1]])\n",
    "y_true = digits.target[-1]\n",
    "print(y_pred)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo prático - Método QR\n",
    "Abaixo calcularemos a decomposição $A = Q R$ em que $Q$ é unitária / ortogonal e $R$ triangular superior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.randn(9,6)\n",
    "q, r = np.linalg.qr(a)\n",
    "np.allclose(a, np.dot(q,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo prático - Método SVD\n",
    "Abaixo faremos uma implementação que consiste em fatorizar a matriz $a$ em duas matrizes unitárias $U$ e $Vh$, e uma matriz $s$ de valores singulares(real não negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "m, n = 9, 6\n",
    "a = np.random.randn(m, n) + 1.j*np.random.randn(m, n)\n",
    "U, s, Vh = linalg.svd(a)\n",
    "U.shape,  s.shape, Vh.shape\n",
    "((9, 9), (6,), (6, 6))\n",
    " \n",
    "#Reconstruir a matriz original a partir da decomposição\n",
    "sigma = np.zeros((m, n))\n",
    "for i in range(min(m, n)):\n",
    "    sigma[i, i] = s[i]\n",
    "    a1 = np.dot(U, np.dot(sigma, Vh))\n",
    "np.allclose(a, a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3 Metodologia da Solução </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de termos formulado o problema e descrito as caixas de ferramentas que utilizaremos e como elas funcionam, descreveremos como o caso de estudo irá ser implementado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Regressão Linear no Scikit Learn\n",
    "Considere um sistema $\\beta = y$, onde tem mais linhas que colunas. Isso ocorre quando você tem mais amostras de dados do que variáveis. Queremos encontrar $\\hat{\\beta}$ isso minimiza:\n",
    " $$ \\big\\vert\\big\\vert X\\beta - y \\big\\vert\\big\\vert_2$$\n",
    " \n",
    " Vamos começar usando a implementação do sklearn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math, scipy, numpy as np\n",
    "from scipy import linalg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn,test,y_trn,y_test = train_test_split(data.data, data.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((353, 10), (89, 10))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.68 ms ± 1.21 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "%timeit regr.fit(trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Será útil ter algumas métricas sobre quao boa é nossa predição. Vamos olhar para a norma quadriculada média(L2) e o erro absoluto médio(L1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_metrics(act, pred):\n",
    "    return (math.sqrt(metrics.mean_squared_error(act, pred)), \n",
    "     metrics.mean_absolute_error(act, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.965123366041944, 40.629875845859964)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_metrics(y_test, regr.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Recursos Polinomais \n",
    "Regressão linear encontra os omelhores coeficientes $\\beta_i$ para:\n",
    "\n",
    "$$x_0\\beta_0+x_1\\beta_1+x_2\\beta_2 = y $$\n",
    "\n",
    "Adicionar recursos polinomiais ainda é um problema de regressão linear, apenas com mais termos:\n",
    "\n",
    "$${x_0\\beta_0+x_1\\beta_1+x_2\\beta_2+x_0^2\\beta_3+x_0x_1\\beta_4+x_1^2\\beta_4+x_0x_2\\beta_5 = y}$$\n",
    "\n",
    "Precisamos usar nossos dados originais para calcular os recursos polinomiais adicionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, queremos tentar melhorar o desempenho do nosso modelo adicionando mais alguns recursos. Atualmente, nosso modelo é linear em cada variável, mas podemos adicionar recursos polinomiais para mudar isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_feat = poly.fit_transform(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'age, sex, bmi, bp, s1, s2, s3, s4, s5, s6, age^2, age sex, age bmi, age bp, age s1, age s2, age s3, age s4, age s5, age s6, sex^2, sex bmi, sex bp, sex s1, sex s2, sex s3, sex s4, sex s5, sex s6, bmi^2, bmi bp, bmi s1, bmi s2, bmi s3, bmi s4, bmi s5, bmi s6, bp^2, bp s1, bp s2, bp s3, bp s4, bp s5, bp s6, s1^2, s1 s2, s1 s3, s1 s4, s1 s5, s1 s6, s2^2, s2 s3, s2 s4, s2 s5, s2 s6, s3^2, s3 s4, s3 s5, s3 s6, s4^2, s4 s5, s4 s6, s5^2, s5 s6, s6^2'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(poly.get_feature_names(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 65)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(trn_feat, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59.10191765786369, 47.190790209969265)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_metrics(y_test, regr.predict(poly.fit_transform(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acelerando a geração de recursos\n",
    "Nos gostariámos de acelerar o desemepenho do nosso modelo. Para isso, nós utilizaremos **Numba** - Compilador - , uma biblioteca Python que compila código diretamente para C. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimentos com vetorização e código nativo\n",
    "Vamos primeiro nos familiarizar com Numba, e então retornaremos ao nosso problema de características polinomiais para regressão no conjunto de dados de diabetes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, numpy as np, matplotlib.pyplot as plt\n",
    "from pandas_summary import DataFrameSummary\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit, vectorize, guvectorize, cuda, float32, void, float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos mostrar o impacto de:\n",
    "\n",
    "- Evitando alocações de memória e cópias (mais lentas que os cálculos da CPU)\n",
    "- Melhor localidade\n",
    "- Vectorização\n",
    "\n",
    "Se usarmos numpy em matrizes inteiras por vez, ele cria muitos temporários e não pode usar o cache. Se usarmos looping numba através de um item da matriz de cada vez, não teremos que alocar grandes matrizes temporárias e reutilizar dados em cache, já que estamos fazendo vários cálculos em cada item da matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untype and Unvectorized\n",
    "def proc_python(xx,yy):\n",
    "    zz = np.zeros(nobs, dtype='float32')\n",
    "    for j in range(nobs):   \n",
    "        x, y = xx[j], yy[j] \n",
    "        x = x*2 - ( y * 55 )\n",
    "        y = x + y*2         \n",
    "        z = x + y + 99      \n",
    "        z = z * ( z - .88 ) \n",
    "        zz[j] = z           \n",
    "    return zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 10000\n",
    "x = np.random.randn(nobs).astype('float32')\n",
    "y = np.random.randn(nobs).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 ms ± 13.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit proc_python(x,y)   # Untyped and unvectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NUMPY**\n",
    "\n",
    "Numpy nos permite vetorizar isso:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typed and Vectorized\n",
    "def proc_numpy(x,y):\n",
    "    z = np.zeros(nobs, dtype='float32')\n",
    "    x = x*2 - ( y * 55 )\n",
    "    y = x + y*2         \n",
    "    z = x + y + 99      \n",
    "    z = z * ( z - .88 ) \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose( proc_numpy(x,y), proc_python(x,y), atol=1e-4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.9 µs ± 8.79 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit proc_numpy(x,y)    # Typed and vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numba** \n",
    "\n",
    "Numba oferece vários decoradores diferentes. Vamos tentar dois diferentes:\n",
    "\n",
    "- @jit: muito geral\n",
    "- @vectorize: não precisa escrever um loop for. útil ao operar em vetores do mesmo tamanho\n",
    "\n",
    "\n",
    "Primeiro, usaremos o decorador de compilador jit (just-in-time) do Numba, sem vetorizar explicitamente. Isso evita grandes alocações de memória, portanto, temos uma melhor localização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def proc_numba(xx,yy,zz):\n",
    "    for j in range(nobs):   \n",
    "        x, y = xx[j], yy[j] \n",
    "        x = x*2 - ( y * 55 )\n",
    "        y = x + y*2         \n",
    "        z = x + y + 99      \n",
    "        z = z * ( z - .88 ) \n",
    "        zz[j] = z           \n",
    "    return zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.zeros(nobs).astype('float32')\n",
    "np.allclose( proc_numpy(x,y), proc_numba(x,y,z), atol=1e-4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 µs ± 1.59 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit proc_numba(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos usar o vectorize decorador do Numba . O compilador do Numba otimiza isso de uma maneira mais inteligente do que é possível com o Python e o Numpy simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize\n",
    "def vec_numba(x,y):\n",
    "    x = x*2 - ( y * 55 )\n",
    "    y = x + y*2         \n",
    "    z = x + y + 99      \n",
    "    return z * ( z - .88 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(vec_numba(x,y), proc_numba(x,y,z), atol=1e-4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.2 µs ± 1.63 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit vec_numba(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, pudemos observar o quanto o Numba é incrível, pois o tempo de processamento caiu em $\\approx$17% ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursos polinomiais da Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def vec_poly(x, res):\n",
    "    m,n=x.shape\n",
    "    feat_idx=0\n",
    "    for i in range(n):\n",
    "        v1=x[:,i]\n",
    "        for k in range(m): res[k,feat_idx] = v1[k]\n",
    "        feat_idx+=1\n",
    "        for j in range(i,n):\n",
    "            for k in range(m): res[k,feat_idx] = v1[k]*x[k,j]\n",
    "            feat_idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = np.asfortranarray(trn)\n",
    "test = np.asfortranarray(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n=trn.shape\n",
    "n_feat = n*(n+1)//2 + n\n",
    "trn_feat = np.zeros((m,n_feat), order='F')\n",
    "test_feat = np.zeros((len(y_test), n_feat), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_poly(trn, trn_feat)\n",
    "vec_poly(test, test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(trn_feat, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59.10191765786377, 47.190790209969194)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_metrics(y_test, regr.predict(test_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.8 µs ± 922 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit vec_poly(trn, trn_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.48 ms ± 110 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit poly.fit_transform(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.57142857142857"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "605/7.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização e ruído\n",
    "A regressão de laço usa uma penalidade de L1, que empurra para coeficientes esparsos. O parâmetro αé usado para ponderar o prazo da penalidade. O LassoCV do Scikit Learn realiza validação cruzada com vários valores diferentes para α"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_regr = linear_model.LassoCV(n_alphas=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=None, copy_X=True, cv='warn', eps=0.001, fit_intercept=True,\n",
       "    max_iter=1000, n_alphas=10, n_jobs=None, normalize=False,\n",
       "    positive=False, precompute='auto', random_state=None,\n",
       "    selection='cyclic', tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_regr.fit(trn_feat, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00990281079884115"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_regr.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.41801675720938, 41.41893271903292)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_metrics(y_test, reg_regr.predict(test_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ruído\n",
    "\n",
    "Agora vamos adicionar algum ruído aos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.random.randint(0, len(trn), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trn2 = np.copy(y_trn)\n",
    "y_trn2[idxs] *= 10 # label noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.965123366041944, 40.62987584585998)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(trn, y_trn)\n",
    "regr_metrics(y_test, regr.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104.28074638703352, 81.96334818991038)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(trn, y_trn2)\n",
    "regr_metrics(y_test, regr.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.62705226456673, 39.89188690667643)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hregr = linear_model.HuberRegressor()\n",
    "hregr.fit(trn, y_trn2)\n",
    "regr_metrics(y_test, hregr.predict(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARTE II "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math, scipy, numpy as np\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn,test,y_trn,y_test = train_test_split(data.data, data.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((353, 10), (89, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_metrics(act, pred):\n",
    "    return (math.sqrt(metrics.mean_squared_error(act, pred)), \n",
    "     metrics.mean_absolute_error(act, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A implementação do sklearn manipulou a adição de um termo constante (já que a interceptação de y não é presumivelmente 0 para a linha que estamos aprendendo) para nós. Vamos precisar fazer isso manualmente agora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_int = np.c_[trn, np.ones(trn.shape[0])]\n",
    "test_int = np.c_[test, np.ones(test.shape[0])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como linalg.lstsqnos permite especificar qual rotina LAPACK queremos usar, vamos experimentar todas e fazer algumas comparações de tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 16.84 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1.03 ms ± 1.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coef, _,_,_ = linalg.lstsq(trn_int, y_trn, lapack_driver=\"gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 µs ± 13 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coef, _,_,_ = linalg.lstsq(trn_int, y_trn, lapack_driver=\"gelsy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 µs ± 17.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coef, _,_,_ = linalg.lstsq(trn_int, y_trn, lapack_driver=\"gelss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposição de Cholesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A^TAx = A^Tb$ Se $A$ tem posto completo, o pseudo-inverso $(A^TA)^-1A^T$ é uma matriz definida positiva hermitiana quadrada. A maneira padrão de resolver esse sistema é a Fatorização de Cholesky, que encontra $R$, ou seja, $A^TA = R^TR$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = trn_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = y_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "AtA = A.T @ A\n",
    "Atb = A.T @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = scipy.linalg.cholesky(AtA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9202,  0.1532,  0.1759,  0.3328,  0.2796,  0.2277, -0.0457,\n",
       "         0.1934,  0.2603,  0.2758, -0.2404],\n",
       "       [ 0.    ,  0.8803,  0.0204,  0.1662,  0.0053,  0.1114, -0.3368,\n",
       "         0.2715,  0.0887,  0.1232,  0.0073],\n",
       "       [ 0.    ,  0.    ,  0.8819,  0.2829,  0.1761,  0.1796, -0.3073,\n",
       "         0.3378,  0.3607,  0.3088,  0.2011],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.7607,  0.0751, -0.0097,  0.0566,\n",
       "        -0.03  ,  0.1551,  0.1106,  0.1039],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.8235,  0.7381,  0.1426,\n",
       "         0.3774,  0.322 ,  0.1695,  0.4743],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.3748, -0.3965,\n",
       "         0.2529, -0.3319, -0.038 , -0.2023],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.6579,\n",
       "        -0.5263, -0.537 , -0.1586, -0.0258],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.297 , -0.0304,  0.0516,  0.0124],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.2877,  0.0771, -0.1997],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ,  0.7264, -0.4307],\n",
       "       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,\n",
       "         0.    ,  0.    ,  0.    , 18.7723]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=4)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.557538200631602e-16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(AtA - R.T @ R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $A^TAx = A^Tb$\n",
    "#### $R^TRx = A^Tb$\n",
    "#### $R^Tw = A^Tb$\n",
    "#### $Rx = w $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = scipy.linalg.solve_triangular(R, Atb, lower=False, trans='T')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É sempre bom verificar que nosso resultado é o que esperamos que seja: (caso tenhamos inserido os parâmetros errados, a função não retornou o que pensávamos, ou às vezes os documentos estão desatualizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2715538963571249e-13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(R.T @ w - Atb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs_chol = scipy.linalg.solve_triangular(R, w, lower=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3791669277752072e-13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(R @ coeffs_chol - w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_chol(A, b):\n",
    "    R = scipy.linalg.cholesky(A.T @ A)\n",
    "    w = scipy.linalg.solve_triangular(R, A.T @ b, trans='T')\n",
    "    return scipy.linalg.solve_triangular(R, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196 µs ± 11.2 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coeffs_chol = ls_chol(trn_int, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48.740042762037284, 39.81160202403081)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_chol = ls_chol(trn_int, y_trn)\n",
    "regr_metrics(y_test, test_int @ coeffs_chol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### QR Fatoração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $Ax = b$\n",
    "#### $A = QR$\n",
    "#### $QRx = b$\n",
    "#### $Rx = Q^Tb$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_qr(A,b):\n",
    "    Q, R = scipy.linalg.qr(A, mode='economic')\n",
    "    return scipy.linalg.solve_triangular(R, Q.T @ b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 µs ± 53.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coeffs_qr = ls_qr(trn_int, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48.74004276203728, 39.811602024030805)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_qr = ls_qr(trn_int, y_trn)\n",
    "regr_metrics(y_test, test_int @ coeffs_qr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####$Ax = b$\n",
    "#### $A = U \\sum V$\n",
    "#### $\\sum Vx = U^Tb$\n",
    "#### $\\sum w = U^Tb$\n",
    "#### $x = V^Tw$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_svd(A,b):\n",
    "    m, n = A.shape\n",
    "    U, sigma, Vh = scipy.linalg.svd(A, full_matrices=False, lapack_driver='gesdd')\n",
    "    w = (U.T @ b)/ sigma\n",
    "    return Vh.T @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266 µs ± 19.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coeffs_svd = ls_svd(trn_int, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48.74004276203728, 39.811602024030805)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_svd = ls_svd(trn_int, y_trn)\n",
    "regr_metrics(y_test, test_int @ coeffs_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipylstq(A, b):\n",
    "    return scipy.linalg.lstsq(A,b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_names = ['Normal Eqns- Naive',\n",
    "             'Normal Eqns- Cholesky', \n",
    "             'QR Factorization', \n",
    "             'SVD', \n",
    "             'Scipy lstsq']\n",
    "\n",
    "name2func = {'Normal Eqns- Naive': 'ls_naive', \n",
    "             'Normal Eqns- Cholesky': 'ls_chol', \n",
    "             'QR Factorization': 'ls_qr',\n",
    "             'SVD': 'ls_svd',\n",
    "             'Scipy lstsq': 'scipylstq'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_array = np.array([100, 1000, 10000])\n",
    "n_array = np.array([20, 100, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_product([m_array, n_array], names=['# rows', '# cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_naive(A, b):\n",
    "     return np.linalg.inv(A.T @ A) @ A.T @ b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.6f}'.format\n",
    "df = pd.DataFrame(index=row_names, columns=index)\n",
    "df_error = pd.DataFrame(index=row_names, columns=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\joaos\\Anaconda1\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# %%prun\n",
    "for m in m_array:\n",
    "    for n in n_array:\n",
    "        if m >= n:        \n",
    "            x = np.random.uniform(-10,10,n)\n",
    "            A = np.random.uniform(-40,40,[m,n])   # removed np.asfortranarray\n",
    "            b = np.matmul(A, x) + np.random.normal(0,2,m)\n",
    "            for name in row_names:\n",
    "                fcn = name2func[name]\n",
    "                t = timeit.timeit(fcn + '(A,b)', number=5, globals=globals())\n",
    "                df.set_value(name, (m,n), t)\n",
    "                coeffs = locals()[fcn](A, b)\n",
    "                reg_met = regr_metrics(b, A @ coeffs)\n",
    "                df_error.set_value(name, (m,n), reg_met[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th># rows</th>\n",
       "      <th colspan=\"3\" halign=\"left\">100</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1000</th>\n",
       "      <th colspan=\"3\" halign=\"left\">10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># cols</th>\n",
       "      <th>20</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>20</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>20</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal Eqns- Naive</th>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.879026</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>0.074231</td>\n",
       "      <td>4.102103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal Eqns- Cholesky</th>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.305701</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.026413</td>\n",
       "      <td>1.586449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QR Factorization</th>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>0.865701</td>\n",
       "      <td>0.066825</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>8.919726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>4.218024</td>\n",
       "      <td>0.040285</td>\n",
       "      <td>0.381846</td>\n",
       "      <td>14.778661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scipy lstsq</th>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.012435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.024232</td>\n",
       "      <td>3.045384</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>0.231698</td>\n",
       "      <td>7.504829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "# rows                   100                    1000                     \\\n",
       "# cols                    20       100  1000     20       100      1000   \n",
       "Normal Eqns- Naive    0.004093 0.002650  NaN 0.000748 0.008992 0.879026   \n",
       "Normal Eqns- Cholesky 0.001407 0.002194  NaN 0.001380 0.003968 0.305701   \n",
       "QR Factorization      0.002009 0.006408  NaN 0.002799 0.022933 0.865701   \n",
       "SVD                   0.005869 0.013510  NaN 0.005033 0.040017 4.218024   \n",
       "Scipy lstsq           0.002265 0.012435  NaN 0.004600 0.024232 3.045384   \n",
       "\n",
       "# rows                   10000                     \n",
       "# cols                    20       100       1000  \n",
       "Normal Eqns- Naive    0.010664 0.074231  4.102103  \n",
       "Normal Eqns- Cholesky 0.006844 0.026413  1.586449  \n",
       "QR Factorization      0.066825 0.345455  8.919726  \n",
       "SVD                   0.040285 0.381846 14.778661  \n",
       "Scipy lstsq           0.022720 0.231698  7.504829  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um 3º exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d3d57a543b4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskew\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRidge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "df = pd.DataFrame(np.column_stack([boston.data, boston.target]),\n",
    "                  columns = np.r_[boston.feature_names, ['MEDV']])\n",
    "print(df.head())\n",
    "\n",
    "sns.set(style='whitegrid', palette='coolwarm')\n",
    "df.plot.box(figsize=(12,6), patch_artist=True)\n",
    "\n",
    "precos = pd.DataFrame({'Preço': df['MEDV'], 'log(Preço + 1)':np.log1p(df['MEDV'])})\n",
    "precos.hist(color='#F1684E', bins=50)\n",
    "plt.ylabel('Quantidade')\n",
    "\n",
    "for col in df.keys():\n",
    "    sk = skew(df[col])\n",
    "    if sk > 0.75:\n",
    "        print(col, sk)\n",
    "\n",
    "\n",
    "dfnorm = (df - df.mean())/(df.std())\n",
    "for x in ['CRIM', 'ZN', 'CHAS', 'MEDV']:\n",
    "    sns.kdeplot(dfnorm[x])\n",
    "\n",
    "plt.plot('Distribuição Valor Médio')\n",
    "plt.xlabel('Preço')\n",
    "plt.ylabel('Quantidade')\n",
    "\n",
    "df.std()\n",
    "\n",
    "dfmin, dfmax = df.min(), df.max()\n",
    "df = (df - df.min())/ (df.max() - df.min())\n",
    "df.std()\n",
    "\n",
    "df.plot.box(figsize=(12,6), patch_artist=True)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest= train_test_split(df.drop('MEDV',1).values, df['MEDV'].values, random_state=201)\n",
    "\n",
    "params = {'alpha': np.linspace(0.1, 1, 200),\n",
    "          'random_state': [2020]}\n",
    "\n",
    "model1 = GridSearchCV(estimator=Ridge(), param_grid=params)\n",
    "model1.fit(xtrain, ytrain)\n",
    "linpred = model1.predict(xtest)\n",
    "\n",
    "err1 = mean_squared_error(linpred, ytest)\n",
    "print(err1)\n",
    "\n",
    "params = {'reg_alpha': np.linspace(0,1,10),\n",
    "          'gamma': np.linspace(0,1,1),\n",
    "          'reg_lambda': np.linspace(0,1,1)}\n",
    "\n",
    "model2 = GridSearchCV(estimator = xgb.XGBRegressor(), param_grid = params)\n",
    "model2.fit(xtrain, ytrain)\n",
    "xgbpred = model2.predict(xtest)\n",
    "\n",
    "err2 = mean_squared_error(xgbpred, ytest)\n",
    "print(err2)\n",
    "\n",
    "predictions = pd.DataFrame({\"XGBoost\":np.expm1(xgbpred), \"Ridge\":np.expm1(linpred)})\n",
    "predictions.plot(x = \"XGBoost\", y = \"Ridge\", kind = \"scatter\", color=\"#85C8DD\")\n",
    "\n",
    "\n",
    "_, _, r_value, _, std_err = stats.linregress(np.expm1(xgbpred),np.expm1(linpred))\n",
    "print(r_value, std_err)\n",
    "\n",
    "err3 = mean_squared_error(xgbpred * 0.8 + linpred * 0.2, ytest) # media ponderada\n",
    "err4 = mean_squared_error((xgbpred + linpred)/2, ytest) # media simples\n",
    "err5 = mean_squared_error(stats.hmean([xgbpred, linpred]), ytest)# media harmonica\n",
    "print(err3, err4, err5)\n",
    "\n",
    "1-err3/err2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Referências Bibliográficas </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Regressão Linear](https://pt.wikipedia.org/wiki/Regress%C3%A3o_linear)\n",
    "- [Jupyter Notebook](https://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/5.%20Health%20Outcomes%20with%20Linear%20Regression.ipynb)\n",
    "- [Regressão Linear part.II](https://pt.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/introduction-to-trend-lines/a/linear-regression-review)\n",
    "- [Videos sobre Regressão](https://www.youtube.com/watch?v=e5dKAK4Df04)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
